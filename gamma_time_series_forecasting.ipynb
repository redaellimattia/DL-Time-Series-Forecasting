{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLhzP7JIUi9D",
        "outputId": "f889cb14-072b-411b-810f-9d84949111d1"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgqzzEaWUW5P"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k42soDObUW5U",
        "outputId": "456d0ba6-8d74-44a5-d17c-b96c72d92cc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import warnings\n",
        "from contextlib import redirect_stdout\n",
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "plt.rc('font', size=16)\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tf.keras.layers\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWk97ZqTUW5W"
      },
      "source": [
        "### Setting Random seed for reproducibility"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaYPq_-KUW5X"
      },
      "outputs": [],
      "source": [
        "seed = 42\n",
        "random.seed(seed)\n",
        "os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "tf.compat.v1.set_random_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv0FfKTRUW5X"
      },
      "source": [
        "## Utils Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5lcXbRYUW5Y"
      },
      "outputs": [],
      "source": [
        "def build_sequences(df, target_labels, window=200, stride=20, telescope=100):\n",
        "    # Sanity check to avoid runtime errors\n",
        "    assert window % stride == 0\n",
        "    dataset_local = []\n",
        "    labels = []\n",
        "    temp_df = df.copy().values\n",
        "    temp_label = df[target_labels].copy().values\n",
        "    padding_len = len(df) % window\n",
        "\n",
        "    if padding_len != 0:\n",
        "        # Compute padding length\n",
        "        padding_len = window - len(df) % window\n",
        "        padding = np.zeros((padding_len, temp_df.shape[1]), dtype='float32')\n",
        "        temp_df = np.concatenate((padding, df))\n",
        "        padding = np.zeros((padding_len, temp_label.shape[1]), dtype='float32')\n",
        "        temp_label = np.concatenate((padding, temp_label))\n",
        "        assert len(temp_df) % window == 0\n",
        "\n",
        "    for idx in np.arange(0, len(temp_df) - window - telescope, stride):\n",
        "        dataset_local.append(temp_df[idx:idx + window])\n",
        "        labels.append(temp_label[idx + window:idx + window + telescope])\n",
        "\n",
        "    dataset_local = np.array(dataset_local)\n",
        "    labels = np.array(labels)\n",
        "    return dataset_local, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hssa3K3UW5Z"
      },
      "outputs": [],
      "source": [
        "def inspect_multivariate(X, y, columns, telescope, idx=None):\n",
        "    if idx is None:\n",
        "        idx = np.random.randint(0, len(X))\n",
        "\n",
        "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17, 17))\n",
        "    for i, col in enumerate(columns):\n",
        "        axs[i].plot(np.arange(len(X[0, :, i])), X[idx, :, i])\n",
        "        axs[i].scatter(np.arange(len(X[0, :, i]), len(X[0, :, i]) + telescope), y[idx, :, i], color='orange')\n",
        "        axs[i].set_title(col)\n",
        "        axs[i].set_ylim(0, 1)\n",
        "    plt.savefig(\"multivariate\", bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def inspect_multivariate_prediction(X_train, X, y, pred, columns, telescope, idx=None):\n",
        "    if idx is None:\n",
        "        idx = np.random.randint(0, len(X))\n",
        "\n",
        "    figs, axs = plt.subplots(len(columns), 1, sharex=True, figsize=(17, 17))\n",
        "    for i, col in enumerate(columns):\n",
        "        axs[i].plot(np.arange(len(X[0, :, i])), X[idx, :, i])\n",
        "        axs[i].plot(np.arange(len(X[0, :, i]), len(X_train[0, :, i]) + telescope), y[idx, :, i], color='orange')\n",
        "        axs[i].plot(np.arange(len(X[0, :, i]), len(X_train[0, :, i]) + telescope), pred[idx, :, i], color='green')\n",
        "        axs[i].set_title(col)\n",
        "        axs[i].set_ylim(0, 1)\n",
        "    plt.savefig(\"multivariate_prediction\", bbox_inches='tight')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXtbSJnBUW5a"
      },
      "source": [
        "## Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rpgp9WhKUW5a",
        "outputId": "140a6190-8b9e-481d-c938-46f17e812582"
      },
      "outputs": [],
      "source": [
        "model_name = 'ATTENTION_LSTM_512_800_5_T_144'\n",
        "%cd /gdrive/My Drive/Colab Notebooks\n",
        "!mkdir ATTENTION_LSTM_512_800_5_T_144\n",
        "\n",
        "# metadata\n",
        "window = 800\n",
        "stride = 5\n",
        "telescope = 144\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "reg_telescope = 864"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY5cfC_zUW5b"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvkGGc7kUW5c",
        "outputId": "2e6ff21b-d217-42e5-84f4-4a9d405d7164"
      },
      "outputs": [],
      "source": [
        "# Load the dataset\n",
        "%cd /gdrive/My Drive/Colab Notebooks/data\n",
        "dataset = pd.read_csv(\"dataset.csv\")\n",
        "target_labels = dataset.columns\n",
        "\n",
        "%cd /gdrive/My Drive/Colab Notebooks/ATTENTION_LSTM_512_800_5_T_144\n",
        "# Print dataset info\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2VGk2ryUW5c"
      },
      "source": [
        "## Inspect the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "eYA-IPNMUW5c",
        "outputId": "70291bbd-123f-4557-8da6-6c6ef26d77d0"
      },
      "outputs": [],
      "source": [
        "figs, axs = plt.subplots(len(dataset.columns), 1, sharex=True, figsize=(17, 17))\n",
        "for i, col in enumerate(dataset.columns):\n",
        "    axs[i].plot(dataset[col])\n",
        "    axs[i].set_title(col)\n",
        "plt.savefig(\"inspect_dataframe\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpa4vvMeUW5d"
      },
      "source": [
        "## Split the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "jPjQkriWUW5d",
        "outputId": "ff287c1f-41c9-476f-ca0f-6bf11ad31e58"
      },
      "outputs": [],
      "source": [
        "# ASSICURARSI CHE LA TEST SIZE SIA MAGGIORE DELLA WINDOW! IN CASO SERVA PIU SPAZIO INCREMENTARE LA TEST_SIZE\n",
        "test_size = int(dataset['Sponginess'].size * 0.1)\n",
        "\n",
        "print('Test raw size: ' + str(test_size))\n",
        "X_train_raw = dataset.iloc[:-test_size]\n",
        "X_test_raw = dataset.iloc[-test_size:]\n",
        "print(\"Train raw shape: \" + str(X_train_raw.shape) + \"  Test raw shape: \" + str(X_test_raw.shape))\n",
        "\n",
        "# Normalize both features and labels\n",
        "X_min = X_train_raw.min()\n",
        "X_max = X_train_raw.max()\n",
        "\n",
        "X_train_raw = (X_train_raw - X_min) / (X_max - X_min)\n",
        "X_test_raw = (X_test_raw - X_min) / (X_max - X_min)\n",
        "\n",
        "plt.figure(figsize=(17, 5))\n",
        "plt.plot(X_train_raw.Sponginess, label='Train (Sponginess)')\n",
        "plt.plot(X_test_raw.Sponginess, label='Test (Sponginess)')\n",
        "plt.title('Train-Test Split')\n",
        "plt.legend()\n",
        "plt.savefig(\"Train-Test_Split\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "future = dataset[-window:]\n",
        "future = (future - X_min) / (X_max - X_min)\n",
        "future = np.expand_dims(future, axis=0)\n",
        "print(\"Future shape: \" + str(future.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BV-UGhSUUW5d",
        "outputId": "de7bfb32-ad13-4de4-ca1c-710f998eee1d"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = build_sequences(X_train_raw, target_labels, window, stride, telescope)\n",
        "X_test, y_test = build_sequences(X_test_raw, target_labels, window, stride, reg_telescope)\n",
        "print(\"X Train shape: \" + str(X_train.shape) + \" Y Train shape: \" + str(y_train.shape))\n",
        "print(\"X Test shape: \" + str(X_test.shape) + \" Y Test shape: \" + str(y_test.shape))\n",
        "\n",
        "inspect_multivariate(X_train, y_train, target_labels, telescope)\n",
        "\n",
        "input_shape = X_train.shape[1:]\n",
        "output_shape = y_train.shape[1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nC7kR5b0UW5e"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEWR-GszUW5e"
      },
      "source": [
        "### Model metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J09xPUuQUW5e"
      },
      "outputs": [],
      "source": [
        "dropout_rate = .3\n",
        "units = 512 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3jbyGcJUW5e"
      },
      "source": [
        "### Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uUMVl14AuW7x"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "class Attention(tfkl.Layer):\n",
        "    def __init__(self, step_dim,\n",
        "                 W_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "        self.supports_masking = True\n",
        "        self.init = tfk.initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = tfk.regularizers.get(W_regularizer)\n",
        "        self.b_regularizer = tfk.regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = tfk.constraints.get(W_constraint)\n",
        "        self.b_constraint = tfk.constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        self.step_dim = step_dim\n",
        "        self.features_dim = 0\n",
        "        super(Attention, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight(shape=(input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        self.features_dim = input_shape[-1]\n",
        "\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight(shape=(input_shape[1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "        else:\n",
        "            self.b = None\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        features_dim = self.features_dim\n",
        "        step_dim = self.step_dim\n",
        "\n",
        "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
        "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
        "\n",
        "        if self.bias:\n",
        "            eij += self.b\n",
        "\n",
        "        eij = K.tanh(eij)\n",
        "\n",
        "        a = K.exp(eij)\n",
        "\n",
        "        if mask is not None:\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0],  self.features_dim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "6MMbl9glUW5f"
      },
      "outputs": [],
      "source": [
        "# Build the neural network layer by layer\n",
        "input_layer = tfkl.Input(shape=input_shape, name='Input')\n",
        "\n",
        "lstm = tfkl.Bidirectional(tfkl.LSTM(units, return_sequences=True),name='BILSTM01')(input_layer)\n",
        "lstm = tfkl.Dropout(dropout_rate, name='DROP01')(lstm)\n",
        "\n",
        "lstm = Attention(input_shape[0])(lstm)\n",
        "lstm = tfkl.RepeatVector(window, name='REP')(lstm)\n",
        "\n",
        "lstm = tfkl.TimeDistributed(tfkl.Dense(units, activation=tfk.layers.LeakyReLU(alpha=0.01)), name='TDDENSE01')(lstm)\n",
        "lstm = tfkl.Dropout(dropout_rate, name='DROP02')(lstm)\n",
        "\n",
        "lstm = tfkl.Bidirectional(tfkl.LSTM(units, return_sequences=True),name='BILSTM02')(lstm)\n",
        "lstm = tfkl.Dropout(dropout_rate, name='DROP03')(lstm)\n",
        "\n",
        "lstm = Attention(input_shape[0])(lstm)\n",
        "\n",
        "# Output: [None, telescope, num_channels]\n",
        "dense = tfkl.Dense(output_shape[-1] * output_shape[-2], activation=tfk.layers.LeakyReLU(alpha=0.01), name='DENSE04')(lstm)\n",
        "output_layer = tfkl.Reshape((output_shape[-2], output_shape[-1]), name='RESHAPE')(dense)\n",
        "\n",
        "# Connect input and output through the Model class\n",
        "model = tfk.Model(inputs=input_layer, outputs=output_layer, name='model')\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=tfk.losses.MeanSquaredError(), optimizer=tfk.optimizers.Adam(), metrics=tf.keras.metrics.RootMeanSquaredError(name=\"rmse\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz4jO6aNUW5f"
      },
      "source": [
        "### Model summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwrE5278Yjet",
        "outputId": "aeb66518-bc17-4bf5-9e3b-52b6f41dacd3"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOgBPww5UW5g"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Z9SEtFiUW5g",
        "outputId": "5aa440e3-ec8e-43a5-af21-35b715e4a633"
      },
      "outputs": [],
      "source": [
        "print(\"Starting training...\")\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    x=X_train,\n",
        "    y=y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=.1,\n",
        "    callbacks=[\n",
        "        tfk.callbacks.EarlyStopping(monitor='val_loss', mode='min', patience=15, restore_best_weights=True),\n",
        "        tfk.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1,\n",
        "                                             mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\n",
        "    ]\n",
        ").history\n",
        "\n",
        "# Save model\n",
        "model.save(model_name)\n",
        "print(\"Model saved!\")\n",
        "model = tfk.models.load_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYsxYpniUW5g"
      },
      "source": [
        "### Plot the training history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "id": "CrB9xXpiUW5g",
        "outputId": "14430347-744f-4266-9033-4563e1f18241"
      },
      "outputs": [],
      "source": [
        "best_epoch = np.argmin(history['val_loss'])\n",
        "plt.figure(figsize=(17, 4))\n",
        "plt.plot(history['loss'], label='Training loss', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_loss'], label='Validation loss', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Mean Squared Error (Loss)')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.savefig(\"val_loss\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(17, 4))\n",
        "plt.plot(history['rmse'], label='Training accuracy', alpha=.8, color='#ff7f0e')\n",
        "plt.plot(history['val_rmse'], label='Validation accuracy', alpha=.9, color='#5a9aa5')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.title('Root Mean Squared Error')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.savefig(\"rmse\", bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(18, 3))\n",
        "plt.plot(history['lr'], label='Learning Rate', alpha=.8, color='#ff7f0e')\n",
        "plt.axvline(x=best_epoch, label='Best epoch', alpha=.3, ls='--', color='#5a9aa5')\n",
        "plt.legend()\n",
        "plt.grid(alpha=.3)\n",
        "plt.title(\"Learning Rate\")\n",
        "plt.savefig(\"learning_rate\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PmY0_16UW5h"
      },
      "source": [
        "## Predict function for autoregressive models (Same for testing and predict the future)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozACCzaKUW5h"
      },
      "outputs": [],
      "source": [
        "def predict(test_data):\n",
        "    predictions = np.array([])\n",
        "    X_temp = test_data\n",
        "    for reg in range(0, reg_telescope, telescope):\n",
        "        pred_temp = model.predict(X_temp)\n",
        "        if len(predictions) == 0:\n",
        "            predictions = pred_temp\n",
        "        else:\n",
        "            predictions = np.concatenate((predictions, pred_temp), axis=1)\n",
        "        X_temp = np.concatenate((X_temp[:, telescope:, :], pred_temp), axis=1)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kFe_XClUW5h"
      },
      "source": [
        "## Start Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9xPrjpUUW5i",
        "outputId": "d7d1fa38-1402-4f11-a1ff-4c03ddbe45af"
      },
      "outputs": [],
      "source": [
        "print(\"Testing...\")\n",
        "predictions = predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qiMes7RpUW5i",
        "outputId": "8d28e03e-1ffc-4d0a-947b-d791d7865d67"
      },
      "outputs": [],
      "source": [
        "denorm_predictions = (tf.convert_to_tensor(predictions, dtype=tf.float32) * (X_max - X_min)) + X_min\n",
        "denorm_predictions = denorm_predictions.numpy()\n",
        "denorm_y_test = (tf.convert_to_tensor(y_test, dtype=tf.float32) * (X_max - X_min)) + X_min\n",
        "denorm_y_test = denorm_y_test.numpy()\n",
        "\n",
        "mse = tfk.metrics.mse(denorm_y_test.flatten(),denorm_predictions.flatten()).numpy()\n",
        "rmse = np.sqrt(mse)\n",
        "print(\"MSE: \"+ str(mse) +\" RMSE: \"+str(rmse))\n",
        "inspect_multivariate_prediction(X_train, X_test, y_test, predictions, target_labels, reg_telescope)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JcxY6ht2UW5f"
      },
      "outputs": [],
      "source": [
        "with open('modelsummary.txt', 'w') as f:\n",
        "    with redirect_stdout(f):\n",
        "        model.summary()\n",
        "        print(\"\\nWINDOW: \"+str(window)+\" STRIDE: \"+str(stride)+\" BATCH SIZE: \"+str(batch_size))\n",
        "        print(\"\\nMSE: \"+ str(mse) +\" RMSE: \"+str(rmse))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8H5ekNgUW5i"
      },
      "source": [
        "## Predict the Future"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JQzGhn1UW5i"
      },
      "source": [
        "### Maes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uk5D9nCoUW5i"
      },
      "outputs": [],
      "source": [
        "maes = []\n",
        "for i in range(predictions.shape[1]):\n",
        "    ft_maes = []\n",
        "    for j in range(predictions.shape[2]):\n",
        "        ft_maes.append(np.mean(np.abs(y_test[:, i, j] - predictions[:, i, j]), axis=0))\n",
        "    ft_maes = np.array(ft_maes)\n",
        "    maes.append(ft_maes)\n",
        "maes = np.array(maes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMOpRKWCUW5j"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u21FjL_zUW5j",
        "outputId": "029e89c2-0969-444d-a4c9-39f6008165d5"
      },
      "outputs": [],
      "source": [
        "print(\"Predict the future...\")\n",
        "future_predictions = predict(future)\n",
        "print(\"Future Prediction shape: \" + str(future_predictions.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRExnRW2UW5j"
      },
      "source": [
        "### Plot the future predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 998
        },
        "id": "URbOk3g7UW5j",
        "outputId": "da105ccd-451e-46f2-bc30-a46369f91528"
      },
      "outputs": [],
      "source": [
        "figs, axs = plt.subplots(len(target_labels), 1, sharex=True, figsize=(17, 17))\n",
        "for i, col in enumerate(target_labels):\n",
        "    axs[i].plot(np.arange(len(future[0, :, i])), future[0, :, i])\n",
        "    axs[i].plot(np.arange(len(future[0, :, i]), len(future[0, :, i]) + reg_telescope), future_predictions[0, :, i],\n",
        "                color='orange')\n",
        "    axs[i].fill_between(\n",
        "        np.arange(len(future[0, :, i]), len(future[0, :, i]) + reg_telescope),\n",
        "        future_predictions[0, :, i] + maes[:, i],\n",
        "        future_predictions[0, :, i] - maes[:, i],\n",
        "        color='orange', alpha=.3)\n",
        "    axs[i].set_title(col)\n",
        "plt.savefig(\"predict\", bbox_inches='tight')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "an2dl-second-homework-autoregressive.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
